q_table_filename: q_table.npy
cell_size: 200
env_width: 3
env_length: 3
env_n_agents: 2
env_n_pickers: 1
env_n_objects: 1
env_enable_rendering: false
episodes: 15000
max_steps_per_episode: 50
discount_factor: 0.99
min_exploration: 0.01
exploration_rate: 1.0
exploration_decay: 0.995
min_learning_rate: 0.01
learning_rate: 0.1
learning_rate_decay: 0.995
